{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lendo o arquivo excel e extraindo os tweets e suas respectivas classificaçoes, sendo 0 = irrelevante e 1 = relevante.\n",
    "data = pd.read_excel(\"mcdonalds_tweets.xlsx\",sheet_name = \"Treinamento\")\n",
    "colunas = [\"Treinamento\", \"Classificação\"]\n",
    "data = data.loc[:,colunas]\n",
    "\n",
    "\n",
    "#Limpando caracteres irrelevantes:\n",
    "#https://pt.stackoverflow.com/questions/217832/como-retirar-caractere-especial-e-ponto-de-coluna-string-de-um-data-frame\n",
    "\n",
    "def deletar_caracteres(coluna):\n",
    "    coluna = coluna.replace(\".\",\" \").replace(\":\",\" \").replace(\",\",\" \").replace(\"'\",\"\").replace('\"', \" \").replace(\"#\",\" \")\\\n",
    "    .replace(\"-\",\"\")\n",
    "    return coluna\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "data['Treinamento'] = data['Treinamento'].apply(deletar_caracteres)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividindo entre relevante e irrelevante e criando um dataframe com os dados\n",
    "Relevante = data[data[\"Classificação\"] == 1]\n",
    "irrel = data[data[\"Classificação\"] == 0] \n",
    "\n",
    "dic_palavras_rel = {}\n",
    "dic_palavras_irrel = {}\n",
    "\n",
    "for i in Relevante[\"Treinamento\"]:\n",
    "    x = i.split()\n",
    "    for e in x:\n",
    "        if e not in dic_palavras_rel:\n",
    "            dic_palavras_rel[e] = 1\n",
    "        \n",
    "        elif e in dic_palavras_rel:\n",
    "            dic_palavras_rel[e] += 1\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "for i in irrel[\"Treinamento\"]:\n",
    "    x = i.split()\n",
    "    for e in x:\n",
    "        if e not in dic_palavras_irrel:\n",
    "            dic_palavras_irrel[e] = 1\n",
    "        \n",
    "        elif e in dic_palavras_irrel:\n",
    "            dic_palavras_irrel[e] += 1\n",
    "            \n",
    "\n",
    "dic_palavras_re = pd.DataFrame.from_dict(dic_palavras_rel, orient='index')\n",
    "dic_palavras_irre =  pd.DataFrame.from_dict(dic_palavras_irrel,  orient='index')\n",
    "\n",
    "\n",
    "dic_palavras_re.columns = [\"Relevante\"]\n",
    "dic_palavras_irre.columns = [\"Irrelevante\"]\n",
    "\n",
    "\n",
    "Dataframe =  dic_palavras_re.join(dic_palavras_irre, how='outer')\n",
    "\n",
    "\n",
    "Dataframe = Dataframe.fillna(0)\n",
    "Dataframe.reset_index(level=0, inplace=True)\n",
    "Dataframe.rename(columns = {\"index\":'Palavras'}, inplace=True)\n",
    "\n",
    "Dataframe['Relevante'] = Dataframe['Relevante'].astype(int)\n",
    "Dataframe['Irrelevante'] = Dataframe['Irrelevante'].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total de palavras relevantes e irrelevantes\n",
    "\n",
    "quantidade_rel = Dataframe.Relevante.sum()\n",
    "\n",
    "quantidade_irrel = Dataframe.Irrelevante.sum() \n",
    "\n",
    "total_palavras = quantidade_rel + quantidade_irrel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probabilidade de palavra/relevante e palavra/irrelevante\n",
    "\n",
    "\n",
    "Dataframe = Dataframe.copy()\n",
    "\n",
    "Dataframe['prob_rel'] = (Dataframe.Relevante + 1) / (quantidade_rel+ total_palavras)\n",
    "Dataframe['prob_irrel'] = (Dataframe.Irrelevante + 1) / (quantidade_irrel+ total_palavras)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59\n",
      "0.41\n"
     ]
    }
   ],
   "source": [
    "# Probabilidade do tweet ser relevante ou irrelevante\n",
    "\n",
    "total_1 = data['Treinamento'][data['Classificação'] == 1].count()\n",
    "total_2 = data['Treinamento'][data['Classificação'] == 0].count()\n",
    "\n",
    "Prelevante = total_1/(total_1+total_2)\n",
    "Pirrelevante = total_2/(total_1+total_2)\n",
    "\n",
    "print(Prelevante)\n",
    "print(Pirrelevante)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probabilidade de relevante/palavra e irrelevante/palavra\n",
    "lis1 = []\n",
    "lis2 = []\n",
    "for e in Dataframe.prob_rel:\n",
    "    lis1.append(e*PRelevante)\n",
    "for e in Dataframe.prob_irrel:\n",
    "    lis2.append(e*Pirrelevante)\n",
    "\n",
    "\n",
    "    \n",
    "Prob = {}    \n",
    "\n",
    "Prob2 = {}\n",
    "        \n",
    "        \n",
    "for i in range(0,len(Dataframe.Relevante)):\n",
    "    Prob[Dataframe.Palavras[i]] = lis1[i]\n",
    "    \n",
    "\n",
    "    \n",
    "for i in range(0,len(Dataframe.Irrelevante)):\n",
    "    Prob2[Dataframe.Palavras[i]] = lis2[i]\n",
    "        \n",
    "index = pd.RangeIndex(start=0, stop=1, step=1)  \n",
    "\n",
    "    \n",
    "dc = pd.DataFrame(data=Prob,index=index)\n",
    "x=dc.T\n",
    "dc0 = pd.DataFrame(data=Prob2,index=index)\n",
    "z=dc0.T\n",
    "x.columns = [\"Relevante_Palavra\"]\n",
    "z.columns = [\"Irrelevante_Palavra\"]\n",
    "\n",
    "Dataframe_Prob =  x.join(z, how='inner')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma funçao para determinar se o tweet é relevante ou irrelevante dado as informações anteriores \n",
    "data_teste = pd.read_excel(\"mcdonalds_tweets.xlsx\",sheet_name = \"Teste\")\n",
    "colunas = [\"Teste\", \"Classificação\"]\n",
    "data_teste = data_teste.loc[:,colunas] \n",
    "data_teste['Teste'] = data_teste['Teste'].apply(deletar_caracteres)\n",
    "\n",
    "lis_teste = []\n",
    "for i in data_teste[\"Teste\"]:\n",
    "    lis_teste.append(i)\n",
    "    \n",
    "\n",
    "\n",
    "def classificar (tweet):\n",
    "    counter_rel = 1\n",
    "    counter_irrel = 1\n",
    "    palavras = tweet.split()\n",
    "    for e in range(len(palavras)):\n",
    "        palavra = palavras[e]\n",
    "        if palavra in Dataframe_Prob.index:\n",
    "            counter_rel *= Prob.get(palavra)\n",
    "            counter_irrel *= Prob2.get(palavra)\n",
    "        if palavra not in Dataframe_Prob.index:\n",
    "            counter_rel *= (0 + 1) / (quantidade_rel+ total_palavras)\n",
    "            counter_irrel *= (0 + 1) / (quantidade_irrel+ total_palavras)\n",
    "            \n",
    "    if counter_rel > counter_irrel:\n",
    "        return 1\n",
    "       \n",
    "        \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "lista  = []      \n",
    "for e in lis_teste:\n",
    "    lista.append(classificar(e))    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "data_teste['Classificados_Bayes'] =  lista\n",
    "\n",
    "\n",
    "                \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descobrindo quantos tweets foram classificados como relevante e irrelevante pelo teorema de bayes e quantos foram\\\n",
    "# previamentes marcados no teste .\n",
    "\n",
    "relevante_teste = data_teste.Classificação.sum()\n",
    "relevante_bayes = data_teste.Classificados_Bayes.sum()\n",
    "\n",
    "irrelevante_teste = 200 - relevante_teste\n",
    "irrelevante_bayes = 200 - relevante_bayes\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevantes no teste : 127 tweets\n",
      "Relevantes no Bayes : 158 tweets\n",
      "irrelevantes no teste : 73 tweets\n",
      "irrelevantes no Bayes : 42 tweets\n",
      "Porcentagem de Acerto: 80.50%\n",
      "Porcentagem de positivos falsos 17.5 %\n",
      "Porcentagem de positivos verdadeiros 61.5 %\n",
      "Porcentagem de negativos verdadeiros 19.0 %\n",
      "Porcentagem de negativos falsos 2.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Relevantes no teste : {0} tweets\".format(relevante_teste))\n",
    "print(\"Relevantes no Bayes : {0} tweets\".format(relevante_bayes))\n",
    "print(\"irrelevantes no teste : {0} tweets\".format(irrelevante_teste))\n",
    "print(\"irrelevantes no Bayes : {0} tweets\".format(irrelevante_bayes))\n",
    "\n",
    "positivos_falsos = 0\n",
    "positivos_verdadeiros = 0 \n",
    "negativos_verdadeiros = 0\n",
    "negativos_falsos = 0\n",
    "\n",
    "for frase,valor in zip(data_teste[\"Teste\"], data_teste[\"Classificação\"]):\n",
    "    bayes = classificar(frase)\n",
    "    if bayes == 1 and int(valor) == 1 :\n",
    "        positivos_verdadeiros +=1\n",
    "    if bayes == 1 and int(valor) == 0:\n",
    "        positivos_falsos += 1\n",
    "    if bayes == 0 and int(valor) == 0:\n",
    "        negativos_verdadeiros +=1\n",
    "    if bayes ==0 and int(valor) ==1:\n",
    "        negativos_falsos +=1\n",
    "        \n",
    "pf = 100*positivos_falsos/200\n",
    "pv = 100*positivos_verdadeiros/200\n",
    "nv = 100*negativos_verdadeiros/200\n",
    "nf = 100*negativos_falsos/200\n",
    "porcentagem = pv +nv\n",
    "\n",
    "print(\"Porcentagem de Acerto: {0:.2f}%\".format(porcentagem))\n",
    "print('Porcentagem de positivos falsos',pf,'%')\n",
    "print('Porcentagem de positivos verdadeiros',pv,'%')\n",
    "print('Porcentagem de negativos verdadeiros',nv,'%')\n",
    "print('Porcentagem de negativos falsos',nf,'%')\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Analizando as medidas obtidas, nota-se que a porcentagem de positivos e negativos verdadeiros, são maiores do que os positivos e negativos falsos, percebe-se também que com a probabilidade padrão de ser relevante de 59 % contra a acurácia de 80,5% obtida pelo algoritimo, o codigo foi eficaz na classificação da relevância dos tweets sobre o McDonald's.\n",
    "    Mensagens de negação e sarcasmo foram tratadas como relevantes, uma vez que elas se referiam, idependentemente de ser positiva ou negativa, ao McDonald's.\n",
    "    Este algorítimo não pode ser usado para melhorar a sua acurácia, devido ao acúmulo de erro. Se sua taxa de acerto inicial é de 80%, usando ele mesmo para aumentar a base de treinamento iria fazer com que sua acurácia decaísse (80% x 80% = 64%).\n",
    "    Esse projeto deve continuar a ser financiado devido ao fato de poder ser aplicado em diferentes tipos de pesquisas. Por exemplo, qual a probabilidade de uma pessoa votar em um certo candidato dado que ela mora em São Paulo, qual a probabiblidade de uma pessoa comprar um ar condicionado dado que ela mora na Bahia ou qual a probabilidade de uma pessoa ter um barco dado que ela mora no Amazonas. Este algoritimo é muito poderoso e é capaz de classificar basicamente qualquer evento binário com uma alta acurácia e de forma quase intantânea. Por isso é tão fundamental seu uso neste tipo de pesquisas.\n",
    "    Entretanto, o algoritimo desconsidera a correlação entre as variáveis, para tornar esse classificador ainda mais eficiente seria nescessario implementar medidas para solucionar esse problema, alguns pesquisadores ja tentam fazer isso através do relaxamento da hipotese de independencia condicional entre os atributos. Outra melhoria para o classificador nesse caso seria desconsiderar os retweets, pois o retweet faz com que a mesma frase apareça diversas vezes fazendo com que a probabilidade de uma mesma palavra aumente, dessa maneira, cria um falso resultado da probabilidade da palavra, prejudicando a acurácia do classificador.\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "   \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
