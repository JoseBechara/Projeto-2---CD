{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Autom√°tico de Sentimento\n",
    "\n",
    "Voc√™ foi contratado por uma empresa parar analisar como os clientes est√£o reagindo a um determinado produto no Twitter. A empresa deseja que voc√™ crie um programa que ir√° analisar as mensagens dispon√≠veis e classificar√° como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mere√ßam destaque, disparem um foco de aten√ß√£o da √°rea de marketing.<br /><br />\n",
    "Como aluno de Ci√™ncia dos Dados, voc√™ lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que √© largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conte√∫do.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, voc√™ precisa implementar uma vers√£o do classificador que \"aprende\" o que √© relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Ap√≥s validado, o seu prot√≥tipo poder√° tamb√©m capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informa√ß√µes do Projeto\n",
    "\n",
    "Prazo: 19/Set at√© √†s 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas ter√° uma rubrica diferenciada.<br /><br />\n",
    "Entreg√°veis via GitHub: \n",
    "* Arquivo notebook com o c√≥digo do classificador, seguindo as orienta√ß√µes abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**N√ÉO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermedi√°ria: Check 1 - APS 2\n",
    "\n",
    "At√© o dia 10/Set √†s 23:59, xlsx deve estar no Github com as seguintes evid√™ncias: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes j√° classificadas.\n",
    "\n",
    "Sugest√£o de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. N√£o se esque√ßa de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. N√£o remover emojis.<br />\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o.\n",
    "\n",
    "Escreva o seu c√≥digo abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@bbcbrasil  jovens colam p√¥ster publicit√°rio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mo√ßo no metr√¥ com um saco do mcdonalds  e agor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@awannable  younghoon tentando falar  mcdona...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@joshhduh  essa hora o mcdonalds ainda n√£o f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@mais_beea  era s√≥ um lanche do mcdonalds pr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@awannable  younghoon tentando falar  mcdona...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@mcdonalds_br  sete dias  sete opo unidades ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@bbcbrasil  estudantes de origem asi√°tica fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nossa queria comprar todas as batatas do mcdon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pelo menos vou passar no mcdonalds de novo kkkk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@bbcbrasil  jovens colam p√¥ster publicit√°rio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>meu deus do c√©u algu√©m quer me comprar um ched...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@rbmps prazer promo√ß√£o do mcdonalds</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>processo pr√©cisos \\nalmo√ßar mcdonald‚Äôs  compra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jovens colam p√¥ster publicit√°rio com foto dele...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@po alrapmais o mcdonalds comprou o spotify po...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>@jxanap tudo cheio de filhos e casas coloridas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>@lexmarkes  @_kingofchevron aaaaaaa j√° vou e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>@izafaria2018  ganhei um lanche do mcdonalds...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>@donghryuck  ‚úé ùëôùë¢ùë§ùëúùëú!¬°ùëéùë¢ ‚úê \\n\\nna qual o uni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>@awannable  younghoon tentando falar  mcdona...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>f5 ‚Äì voc√™ viu? ‚Äì jovens colam p√¥ster ‚Äòpublicit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>meu namorado passou no mcdonald‚Äôs dps do curso...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>@vocesabia  em m√©dia  levaria cerca de 4 a 7...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>@mcdonalds_br  uma novidade de enlouquecer  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>o spo ing √© o clube mais imbecil do planeta   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>@laylindabj  s√≥ queria um lanche do mcdonald...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>@srdeabo t√° explicado  mccarol  tudo do mcdona...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>@donghryuck  ‚úé ùëôùë¢ùë§ùëúùëú!¬°ùëéùë¢ ‚úê \\n\\nna qual o uni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>@isabellameeloo  sinto que quando abrir esse...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>@awannable  younghoon tentando falar  mcdona...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>minha fam√≠lia toda foi no mcdonalds e quem t√° ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>ay on traindo o brother e comendo lanche do mc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>@transito_rjo   rdrj   @bbcbrasil  jovens co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>amanh√£ vou no mcdonalds dps da escola ü§î</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>boleia ervidelbeja agora  queremos ir ao mcdon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>@bbcbrasil  jovens colam p√¥ster publicit√°rio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>gra√ßas aos c√©us n√£o recebi hoje porque s√≥ isso...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>o √°pice da noite √© meu tio e minha av√≥ discuti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>t√¥ querendo ir no mcdonalds</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>jovens colam p√¥ster publicit√°rio com foto dele...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>vou levar meus irm√£os no mcdonalds mais tarde</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>@almeidinha34slb  eu casome com quem chegar ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>@castrolaysi  s√≥ queria um lanche do mcdonal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>@ricardooliv1704  burger king √© bem melhor d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>mcdonalds quase √†s 2h da manh√£  j√° n√£o me lemb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>ela quer ser o meu c√¥njuge  juro que n√£o enlou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>@isabellameeloo  sinto que quando abrir esse...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>m√≥ vontade de ir no mcdonalds man√©   üôÑüíîüçüüçüüçî</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>@ricardooliv1704  burger king √© bem melhor d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>sobre ela ir no mcdonalds e ainda me avisar qu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>estudantes de origem asi√°tica fingem pe√ßa publ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>fotos no wc do mcdonalds quem nunca https //t ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>@joaomsilvaf  o mcdonald‚Äôs √© aquele s√≠tio a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>vamos no mcdonalds? ‚Äî mc n√£o kkkkkkkk https //...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>@ricardooliv1704  burger king √© bem melhor d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>@canalnerdshow @youtube faz sim sobre a hist√≥r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>@bbcbrasil  estudantes de origem asi√°tica fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>encontrei pe rufino no mcdonalds  mano que hom...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>pois bem o cara que senta do meu lado acabou d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  Classifica√ß√£o\n",
       "0      @bbcbrasil  jovens colam p√¥ster publicit√°rio...              0\n",
       "1    mo√ßo no metr√¥ com um saco do mcdonalds  e agor...              1\n",
       "2      @awannable  younghoon tentando falar  mcdona...              0\n",
       "3      @joshhduh  essa hora o mcdonalds ainda n√£o f...              1\n",
       "4      @mais_beea  era s√≥ um lanche do mcdonalds pr...              1\n",
       "5      @awannable  younghoon tentando falar  mcdona...              0\n",
       "6      @mcdonalds_br  sete dias  sete opo unidades ...              1\n",
       "7      @bbcbrasil  estudantes de origem asi√°tica fi...              0\n",
       "8    nossa queria comprar todas as batatas do mcdon...              1\n",
       "9      pelo menos vou passar no mcdonalds de novo kkkk              1\n",
       "10     @bbcbrasil  jovens colam p√¥ster publicit√°rio...              0\n",
       "11   meu deus do c√©u algu√©m quer me comprar um ched...              1\n",
       "12                 @rbmps prazer promo√ß√£o do mcdonalds              0\n",
       "13   processo pr√©cisos \\nalmo√ßar mcdonald‚Äôs  compra...              1\n",
       "14   jovens colam p√¥ster publicit√°rio com foto dele...              0\n",
       "15   @po alrapmais o mcdonalds comprou o spotify po...              0\n",
       "16   @jxanap tudo cheio de filhos e casas coloridas...              1\n",
       "17     @lexmarkes  @_kingofchevron aaaaaaa j√° vou e...              1\n",
       "18     @izafaria2018  ganhei um lanche do mcdonalds...              1\n",
       "19     @donghryuck  ‚úé ùëôùë¢ùë§ùëúùëú!¬°ùëéùë¢ ‚úê \\n\\nna qual o uni...              0\n",
       "20     @awannable  younghoon tentando falar  mcdona...              0\n",
       "21   f5 ‚Äì voc√™ viu? ‚Äì jovens colam p√¥ster ‚Äòpublicit...              0\n",
       "22   meu namorado passou no mcdonald‚Äôs dps do curso...              1\n",
       "23     @vocesabia  em m√©dia  levaria cerca de 4 a 7...              1\n",
       "24     @mcdonalds_br  uma novidade de enlouquecer  ...              1\n",
       "25   o spo ing √© o clube mais imbecil do planeta   ...              0\n",
       "26     @laylindabj  s√≥ queria um lanche do mcdonald...              1\n",
       "27   @srdeabo t√° explicado  mccarol  tudo do mcdona...              1\n",
       "28     @donghryuck  ‚úé ùëôùë¢ùë§ùëúùëú!¬°ùëéùë¢ ‚úê \\n\\nna qual o uni...              0\n",
       "29     @isabellameeloo  sinto que quando abrir esse...              1\n",
       "..                                                 ...            ...\n",
       "270    @awannable  younghoon tentando falar  mcdona...              0\n",
       "271  minha fam√≠lia toda foi no mcdonalds e quem t√° ...              1\n",
       "272  ay on traindo o brother e comendo lanche do mc...              0\n",
       "273    @transito_rjo   rdrj   @bbcbrasil  jovens co...              0\n",
       "274            amanh√£ vou no mcdonalds dps da escola ü§î              1\n",
       "275  boleia ervidelbeja agora  queremos ir ao mcdon...              0\n",
       "276    @bbcbrasil  jovens colam p√¥ster publicit√°rio...              0\n",
       "277  gra√ßas aos c√©us n√£o recebi hoje porque s√≥ isso...              1\n",
       "278  o √°pice da noite √© meu tio e minha av√≥ discuti...              0\n",
       "279                        t√¥ querendo ir no mcdonalds              1\n",
       "280  jovens colam p√¥ster publicit√°rio com foto dele...              0\n",
       "281      vou levar meus irm√£os no mcdonalds mais tarde              0\n",
       "282    @almeidinha34slb  eu casome com quem chegar ...              1\n",
       "283    @castrolaysi  s√≥ queria um lanche do mcdonal...              1\n",
       "284    @ricardooliv1704  burger king √© bem melhor d...              1\n",
       "285  mcdonalds quase √†s 2h da manh√£  j√° n√£o me lemb...              1\n",
       "286  ela quer ser o meu c√¥njuge  juro que n√£o enlou...              0\n",
       "287    @isabellameeloo  sinto que quando abrir esse...              1\n",
       "288         m√≥ vontade de ir no mcdonalds man√©   üôÑüíîüçüüçüüçî              1\n",
       "289    @ricardooliv1704  burger king √© bem melhor d...              1\n",
       "290  sobre ela ir no mcdonalds e ainda me avisar qu...              1\n",
       "291  estudantes de origem asi√°tica fingem pe√ßa publ...              0\n",
       "292  fotos no wc do mcdonalds quem nunca https //t ...              0\n",
       "293    @joaomsilvaf  o mcdonald‚Äôs √© aquele s√≠tio a ...              1\n",
       "294  vamos no mcdonalds? ‚Äî mc n√£o kkkkkkkk https //...              1\n",
       "295    @ricardooliv1704  burger king √© bem melhor d...              1\n",
       "296  @canalnerdshow @youtube faz sim sobre a hist√≥r...              0\n",
       "297    @bbcbrasil  estudantes de origem asi√°tica fi...              0\n",
       "298  encontrei pe rufino no mcdonalds  mano que hom...              0\n",
       "299  pois bem o cara que senta do meu lado acabou d...              1\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 806,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"mcdonalds_tweets.xlsx\",sheet_name = \"Treinamento\")\n",
    "colunas = [\"Treinamento\", \"Classifica√ß√£o\"]\n",
    "data = data.loc[:,colunas]\n",
    "\n",
    "\n",
    "#Limpando caracteres irrelevantes:\n",
    "\n",
    "def deletar_caracteres(coluna):\n",
    "    coluna = coluna.replace(\".\",\" \").replace(\":\",\" \").replace(\",\",\" \").replace(\"'\",\"\").replace('\"', \" \").replace\\\n",
    "    (\"rt\",\" \").replace(\"#\",\" \").replace(\"-\",\"\")\n",
    "    return coluna\n",
    "\n",
    "    \n",
    "\n",
    "data['Treinamento'] = data['Treinamento'].apply(deletar_caracteres)\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividindo entre relevante e irrelevante\n",
    "Relevante = data[data[\"Classifica√ß√£o\"] == 1]\n",
    "irrel = data[data[\"Classifica√ß√£o\"] == 0] \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = data[\"Treinamento\"]\n",
    "dic_palavras_rel = {}\n",
    "dic_palavras_irrel = {}\n",
    "\n",
    "for i in Relevante[\"Treinamento\"]:\n",
    "    x = i.split()\n",
    "    for e in x:\n",
    "        if e not in dic_palavras_rel:\n",
    "            dic_palavras_rel[e] = 1\n",
    "        \n",
    "        elif e in dic_palavras_pos:\n",
    "            dic_palavras_rel[e] += 1\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "for i in irrel[\"Treinamento\"]:\n",
    "    x = i.split()\n",
    "    for e in x:\n",
    "        if e not in dic_palavras_irrel:\n",
    "            dic_palavras_irrel[e] = 1\n",
    "        \n",
    "        elif e in dic_palavras_irrel:\n",
    "            dic_palavras_irrel[e] += 1\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palavras</th>\n",
       "      <th>Relevante</th>\n",
       "      <th>Irrelevante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&amp;amp;</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&amp;gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(@</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(sabado</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>//t</td>\n",
       "      <td>37</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123m</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Palavras  Relevante  Irrelevante\n",
       "0    &amp;          0            1\n",
       "1     &gt;          0            8\n",
       "2       (@          2            0\n",
       "3  (sabado          1            0\n",
       "4      //t         37           65\n",
       "5      000          1            0\n",
       "6       01          1            0\n",
       "7        1          1            0\n",
       "8       10          1            1\n",
       "9     123m          0            1"
      ]
     },
     "execution_count": 825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df2 = pd.DataFrame.from_dict(dic_palavras_rel, orient='index')\n",
    "df0 =  pd.DataFrame.from_dict(dic_palavras_irrel,  orient='index')\n",
    "\n",
    "\n",
    "df2.columns = [\"Relevante\"]\n",
    "df0.columns = [\"Irrelevante\"]\n",
    "\n",
    "\n",
    "Dataframe =  df2.join(df0, how='outer')\n",
    "\n",
    "\n",
    "Dataframe = Dataframe.fillna(0)\n",
    "Dataframe.reset_index(level=0, inplace=True)\n",
    "Dataframe.rename(columns = {\"index\":'Palavras'}, inplace=True)\n",
    "\n",
    "Dataframe['Relevante'] = Dataframe['Relevante'].astype(int)\n",
    "Dataframe['Irrelevante'] = Dataframe['Irrelevante'].astype(int)\n",
    "Dataframe.head(10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2448\n",
      "2012\n"
     ]
    }
   ],
   "source": [
    "# Total de palavras positivas, negativas e irrelevantes\n",
    "\n",
    "quantidade_rel = 0\n",
    "\n",
    "quantidade_irrel = 0  \n",
    "\n",
    "\n",
    "for e in Dataframe.Relevante:\n",
    "    quantidade_rel +=e\n",
    "    \n",
    "    \n",
    "        \n",
    "for f in Dataframe.Irrelevante:\n",
    "        quantidade_irrel +=f \n",
    "        \n",
    "print(quantidade_rel)    \n",
    "\n",
    "print(quantidade_irrel)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PalavraRelevante</th>\n",
       "      <th>PalavraIrrelevante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&amp;amp;</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&amp;gt;</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(@</th>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(sabado</th>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>//t</th>\n",
       "      <td>0.015114</td>\n",
       "      <td>0.032306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123m</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PalavraRelevante  PalavraIrrelevante\n",
       "&amp;            0.000000            0.000497\n",
       "&gt;             0.000000            0.003976\n",
       "(@               0.000817            0.000000\n",
       "(sabado          0.000408            0.000000\n",
       "//t              0.015114            0.032306\n",
       "000              0.000408            0.000000\n",
       "01               0.000408            0.000000\n",
       "1                0.000408            0.000000\n",
       "10               0.000408            0.000497\n",
       "123m             0.000000            0.000497"
      ]
     },
     "execution_count": 811,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probabilidade de palavra/relevante\n",
    "dic2 = {}\n",
    "\n",
    "dic0 = {}\n",
    "lista2 = []\n",
    "\n",
    "lista0 = []\n",
    "\n",
    "for e in Dataframe.Relevante:\n",
    "    lista2.append((e/quantidade_rel))\n",
    "  \n",
    "    \n",
    "for e in Dataframe.Irrelevante:\n",
    "    lista0.append((e/quantidade_irrel))\n",
    "    \n",
    "    \n",
    "for i in range(0,len(Dataframe.Relevante)):\n",
    "    dic2[Dataframe.Palavras[i]] = lista2[i]\n",
    "    \n",
    "\n",
    "    \n",
    "for i in range(0,len(Dataframe.Irrelevante)):\n",
    "    dic0[Dataframe.Palavras[i]] = lista0[i]\n",
    "        \n",
    "index = pd.RangeIndex(start=0, stop=1, step=1)  \n",
    "\n",
    "    \n",
    "dc2 = pd.DataFrame(data=dic2,index=index)\n",
    "x=dc2.T\n",
    "dc0 = pd.DataFrame(data=dic0,index=index)\n",
    "z=dc0.T\n",
    "x.columns = [\"PalavraRelevante\"]\n",
    "z.columns = [\"PalavraIrrelevante\"]\n",
    "\n",
    "Dataframe2 =  x.join(z, how='inner')\n",
    "Dataframe2.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P(Palavra)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&amp;amp;</th>\n",
       "      <td>0.000448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&amp;gt;</th>\n",
       "      <td>0.003587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(@</th>\n",
       "      <td>0.000897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(sabado</th>\n",
       "      <td>0.000448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>//t</th>\n",
       "      <td>0.045740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>0.000448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>0.000448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123m</th>\n",
       "      <td>0.000448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>0.000448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2h</th>\n",
       "      <td>0.000448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3h</th>\n",
       "      <td>0.000448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.000448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         P(Palavra)\n",
       "&amp;      0.000448\n",
       "&gt;       0.003587\n",
       "(@         0.000897\n",
       "(sabado    0.000448\n",
       "//t        0.045740\n",
       "000        0.000448\n",
       "01         0.000448\n",
       "1          0.000448\n",
       "10         0.000897\n",
       "123m       0.000448\n",
       "15         0.000448\n",
       "2          0.001794\n",
       "20         0.000897\n",
       "2004       0.000448\n",
       "2h         0.000448\n",
       "3          0.000897\n",
       "30         0.000448\n",
       "3h         0.000448\n",
       "4          0.000897\n",
       "40         0.000448"
      ]
     },
     "execution_count": 829,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probabilidade da palavra\n",
    "total_palavras = quantidade_rel + quantidade_irrel\n",
    "\n",
    "Dataframe['Total'] = Dataframe.iloc[:, 1:].sum(axis=1)\n",
    "lista =  []\n",
    "dic = {}\n",
    "\n",
    "    \n",
    "for e in Dataframe.Total:\n",
    "    lista.append((e/total_palavras))\n",
    "    \n",
    "for i in range(0,len(Dataframe.Total)):\n",
    "    dic[Dataframe.Palavras[i]] = lista[i]    \n",
    "    \n",
    "index = pd.RangeIndex(start=0, stop=1, step=1)  \n",
    "\n",
    "    \n",
    "Dataframe3 = pd.DataFrame(data=dic,index=index)        \n",
    "Dataframe3 = Dataframe3.T  \n",
    "Dataframe3.columns = [\"P(Palavra)\"]\n",
    "\n",
    "Dataframe3.head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59\n",
      "0.41\n"
     ]
    }
   ],
   "source": [
    "total_1 = data['Treinamento'][data['Classifica√ß√£o'] == 1].count()\n",
    "total_2 = data['Treinamento'][data['Classifica√ß√£o'] == 0].count()\n",
    "\n",
    "PRelevante = total_1/(total_1+total_2)\n",
    "Pirrelevante = total_2/(total_1+total_2)\n",
    "\n",
    "print(PRelevante)\n",
    "print(Pirrelevante)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'PalavraPositivo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-814-43cc64ad91e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlista\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlista3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mDataframe2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPalavraPositivo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mlista\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mDataframe3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPPalavra\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   3612\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3613\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3614\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3616\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'PalavraPositivo'"
     ]
    }
   ],
   "source": [
    "lista2 = []\n",
    "lista = []\n",
    "lista3 = []\n",
    "for e in Dataframe2.PalavraPositivo:\n",
    "    lista.append(e)\n",
    "for e in Dataframe3.PPalavra:\n",
    "    lista2.append(e)\n",
    "\n",
    "\n",
    "    \n",
    "dic = {}    \n",
    "pp=[]\n",
    "#probabilidade de Relevante/Palavra\n",
    "\n",
    "for e in lista:\n",
    "        pp.append(f * Pp)\n",
    "     \n",
    "\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Voc√™ deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas n√£o s√£o relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e s√£o relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como n√£o relevante e n√£o s√£o relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como n√£o relevante e s√£o relevantes)\n",
    "\n",
    "Obrigat√≥rio para grupos de 3 alunos:\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseado na diferen√ßa de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclus√£o.<br /> \n",
    "Fa√ßa um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como s√£o tratadas as mensagens com dupla nega√ß√£o e sarcasmo.<br />\n",
    "Proponha um plano de expans√£o. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que n√£o posso alimentar minha base de Treinamento automaticamente usando o pr√≥prio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cen√°rios de uso para o classificador Naive-Bayes. Cen√°rios sem intersec√ß√£o com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indica√ß√µes concretas de como implementar (n√£o √© preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
